{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Homework 2\"\n",
        "format: html\n",
        "---\n",
        "\n",
        "\n",
        "__Due Date:__ 2022-10-16 at 8:30 AM PT\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "__Name:__ Luke Schlake\n",
        "\n",
        "\n",
        "\n",
        "For this assignment, you will practice downloadings, cleaning, and analyzing data from the [National Risk Index (NRI)](https://hazards.fema.gov/nri/) and the [CDC Social Vulnerability Index (SVI)](https://www.atsdr.cdc.gov/placeandhealth/svi/index.html).\n",
        "\n",
        "## Preparation\n",
        "\n",
        "1. Create a 'data' folder in the root directory of this repository.\n",
        "1. Inside the 'data' folder, create a 'raw' folder.\n",
        "1. Add and commit a '.gitignore' file to the root directory of this repository that excludes all contents of the 'data' folder.\n",
        "1. Download the county-level NRI and SVI data for the entire United States. Place the data in the 'data/raw' folder.\n",
        "1. In the repository README, provide a brief (1-2 sentence) description of each file in the 'data' folder and a link to the original source of the data.\n",
        "\n",
        "## Task 1 - NRI Data Cleaning\n",
        "\n",
        "__1. Import the NRI data. Ensure that the [FIPS code](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code) variable ('STCOFIPS') is correctly identified as a string / character variable. Otherwise, the leading zeros will be removed.__"
      ],
      "id": "7947a8b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import zipfile \n",
        "\n",
        "with zipfile.ZipFile(\"data/raw/NRI_Table_Counties.zip\",\"r\") as f:\n",
        "    f.extractall(\"data/raw/NRI\")\n",
        "\n",
        "NRI_data= pd.read_csv(\"data/raw/NRI/NRI_Table_Counties.csv\")"
      ],
      "id": "ebf778f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SVI_data.head(10)\n",
        "NRI_data.head(10)\n",
        "print(NRI_data.columns)"
      ],
      "id": "18982f72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "NRI_data[\"STCOFIPS\"]"
      ],
      "id": "321caf84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__2. Subset the NRI data to include only the 5-digit state/county FIPS code and all colums ending with '\\_AFREQ' and '\\_RISKR'. Each of these columns represents a different hazard type.__"
      ],
      "id": "0c5f7326"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Filter for specific columns \n",
        "NRI_filtered = pd.DataFrame()\n",
        "NRI_filtered[\"FIPS\"] = NRI_data[\"STCOFIPS\"]\n",
        "for p in NRI_data.columns:\n",
        "    if p.endswith(\"_AFREQ\") | p.endswith(\"_RISKR\"):\n",
        "        NRI_filtered[p]=NRI_data[p]\n",
        "NRI_filtered.columns\n"
      ],
      "id": "46699a1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__3. Create a table / dataframe that, for each hazard type, shows the number of missing values in the '\\_AFREQ' and '\\_RISKR' columns.__"
      ],
      "id": "f3eef79f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.DataFrame(NRI_filtered.isnull().sum())\n",
        "print(data)\n",
        "#text"
      ],
      "id": "b64b1f43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__4. Show the cross-tabulation of the 'AVLN_AFREQ' and 'AVLN_RISKR' columns (including missing values). What do you observe?__"
      ],
      "id": "5251e1ce"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "crosstab = pd.crosstab(NRI_filtered[\"AVLN_AFREQ\"],NRI_filtered[\"AVLN_RISKR\"])\n",
        "print(crosstab)"
      ],
      "id": "3d27c0be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__5. Assuming that a risk that is \"not applicable\" to a county has an annualized frequency of 0, impute the relevant missing values in the '\\_AFREQ' columns with 0.__"
      ],
      "id": "f5e6c089"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for p in NRI_data.columns:\n",
        "    if p.endswith(\"_AFREQ\"):\n",
        "        NRI_filtered[p]=NRI_data[p].fillna(0)\n",
        "\n",
        "NRI_filtered[\"FIPS\"]=NRI_filtered[\"FIPS\"].astype(str)"
      ],
      "id": "2c3d9004",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2 - SVI Data Cleaning\n",
        "\n",
        "__1. Import the SVI data. Ensure that the FIPS code is correctly identified as a string / character variable. Otherwise, the leading zeros will be removed.__"
      ],
      "id": "8abf33f8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SVI_data= pd.read_csv(\"data/raw/SVI_2022_US_county.csv\")\n",
        "SVI_data[\"FIPS\"]=SVI_data[\"FIPS\"].astype(str)\n",
        "#FIPS is successfully changed to an object"
      ],
      "id": "9584990b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__1. Subset the SVI data to include only the following columns:__\n",
        "`ST, STATE, ST_ABBR, STCNTY, COUNTY, FIPS, LOCATION, AREA_SQMI, E_TOTPOP, EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, EP_GROUPQ, EP_NOINT, EP_AFAM, EP_HISP, EP_ASIAN, EP_AIAN, EP_NHPI, EP_TWOMORE, EP_OTHERRACE`"
      ],
      "id": "feba039f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "list = [\"ST\", \"STATE\", \"ST_ABBR\", \"STCNTY\", \"COUNTY\", \"FIPS\", \"LOCATION\", \"AREA_SQMI\", \"E_TOTPOP\", \"EP_POV150\", \"EP_UNEMP\", \"EP_HBURD\", \"EP_NOHSDP\", \"EP_UNINSUR\", \"EP_AGE65\", \"EP_AGE17\", \"EP_DISABL\", \"EP_SNGPNT\", \"EP_LIMENG\", \"EP_MINRTY\", \"EP_MUNIT\", \"EP_MOBILE\", \"EP_CROWD\", \"EP_NOVEH\", \"EP_GROUPQ\", \"EP_NOINT\", \"EP_AFAM\", \"EP_HISP\", \"EP_ASIAN\", \"EP_AIAN\", \"EP_NHPI\", \"EP_TWOMORE\", \"EP_OTHERRACE\"]\n",
        "\n",
        "SVI_filtered=pd.DataFrame()\n",
        "\n",
        "for x in list:\n",
        "    SVI_filtered[x]=SVI_data[x]\n",
        "\n",
        "SVI_filtered[\"FIPS\"]=SVI_filtered[\"FIPS\"].astype(str)\n",
        "NRI_filtered[\"FIPS\"]=NRI_filtered[\"FIPS\"].astype(str)"
      ],
      "id": "40624761",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__2. Create a table / dataframe that shows the number of missing values in each column. (Hint: if you wrote a function for Task 1, you can reuse it here.)__"
      ],
      "id": "98c5640c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.DataFrame(SVI_filtered.isnull().sum())\n",
        "print(data)"
      ],
      "id": "a4ce1358",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3 - Data Merging\n",
        "__1. Identify any FIPS codes that are present in the NRI data but not in the SVI data and vice versa. Describe any discrepancies and possible causes? What to these discrepancies, if any, mean for interpreting results based on the merged dataset moving forward?__"
      ],
      "id": "e1ecb058"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#All the missing NRI missing FIPS codes in the SVI begin with 7 and are 5 digits (or are close to a FIPS code beginning with 7, ex: 69001)\n",
        "#I used RANDChat for this block to determine the use of the .isin function\n",
        "NRI_filtered[\"matches\"] = NRI_filtered[\"FIPS\"].isin(SVI_filtered[\"FIPS\"])\n",
        "NRI_filtered[[\"matches\",\"FIPS\"]].sort_values(by=\"matches\",ascending=True)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "NRI_filtered[[\"matches\",\"FIPS\"]]"
      ],
      "id": "75958c1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#All the missing NRI missing FIPS codes in the SVI begin with 9 and are 4 digits\n",
        "SVI_filtered[\"matches\"] = SVI_filtered[\"FIPS\"].isin(NRI_filtered[\"FIPS\"])\n",
        "SVI_filtered[[\"matches\",\"FIPS\"]].sort_values(by=\"matches\",ascending=False)"
      ],
      "id": "46e83f9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__2. Merge the NRI and SVI data on the FIPS code. Use an outer join to keep all counties in the final dataset.__"
      ],
      "id": "0c44c305"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_data = pd.merge(SVI_filtered, NRI_filtered, on=\"FIPS\",how=\"outer\")\n",
        "merged_data.head(10)"
      ],
      "id": "9a8e3a0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__3. Create a table / dataframe that shows the number of missing values in each column of the merged dataset.__"
      ],
      "id": "bc956aaa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "missing_data=merged_data.isnull().sum()\n",
        "missing_data"
      ],
      "id": "6e1ebc01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4 - Data Analysis\n",
        "\n",
        "__1. For each numerical variable in the merged dataset, plot a histogram showing the distribution of values. (Hint: write a function to make the histogram for a single variable, then use a loop or apply function to make the histograms for all numerical variables.)__"
      ],
      "id": "5b0cab91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#I used RANDchat to generate the is_number function and to see how the .apply/.all function was used to call is_number\n",
        "\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "for p in merged_data.columns:\n",
        "    numeric = merged_data[p].apply(is_number).all()\n",
        "    if numeric==True:\n",
        "        print(p)\n",
        "        plt.hist(merged_data[p])\n",
        "        plt.show()"
      ],
      "id": "9c977a98",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}